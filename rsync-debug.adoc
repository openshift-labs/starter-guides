## Lab: Day to Day Development

### Moving on From S2I
As you saw before S2I is a great way to get from source code to a container, but the process is a bit too slow for daily fast iteration
development. For example, if you want to change some CSS or change one method in a class you don't want to go through
a full git commit and build cycle. In this lab we are going to show you a more efficient method for quick iteration. While
we are at it we will also throw in showing you how to debug your code as well.

Now that we built the MLB parks service let's go ahead and make some quick changes

### Fast Iteration Code Change Using Rsync

The OpenShift command line has the rsync command built in. If you are on Windows and don't have rsync installed, the command
will fall back to tar, which will work but some of the flags won't work.

To see the options available go ahead look at the command line help on your local machine:

[source, bash,role=copypaste]
---
oc rsync --help
---

We are going to use the --watch flag to have rsync continuously monitor the local directory and upload the contents to the pod.
Since EAP supports live reload of WAR files we are going to build the WAR file locally and upload it to the running pod.

WARNING: These changes will not be persisted in the pod since we are changing an ephemeral disk store. If you want to "save"
your changes to the image you will need to go through the full S2I cycle and build a new image.

#### Exercise: Using Rsync to do normal iteration

##### Clone source
The first step is to clone the MLB source code from GitHub to your local machine:

[source, bash,role=copypaste]
---
git clone https://github.com/openshift-roadshow/mlbparks.git
---

NOTE: We are using Intellij here in the guide for screenshots but this should work regardless of your tool chain. JBoss
Developer Studio and JBoss Developer Tools have built in functionality that makes this close to seamless right from the IDE.

##### Setup the Build of the war file

**Maven**

If you have Maven all set up on your machine, then you can just do a

[source, bash,role=copypaste]
----

mvn package

----

Pay attention to the output location for the ROOT.war, we will need that directory later.

**Intellij**

In Intellij, once the project is imported, we need to create a configuration to build an artifact

Go to Project Structure
image::rsync-properties.png[Intellij Properties]

Then got to Modules, where you will see a notice that web facet resources is not included in the artifact. Click the "create
artifact" button, which will bring you to the next page in the process

image::rsync-createartifact.png[Module Properties]

Now on this page, Intellij will try to create an exploded archive, we don't want that. So on the top right change the drop
down to _Web Application: Archive_. Then change the name to _ROOT_ which should also change the output layout to ROOT.war.
Finally, either change the output directory to the location you want for the war file or just note the location autogenerated.

image::rsync-newartifact.png[Intellij Properties]

Finally make sure to click Apply.

Now you can generate artifacts and it will make the ROOT.war file. Build artifacts is located under the build menu ( I have
mapped it to ctrl-shift-f10).

##### Code Change
Time for a source code change! Go to src/main/java/com/openshift/evg/roadshow/rest/BackendController.java. This is the REST endpoint
that gives basic info on the service and can be reached at

http://mlbparks-{{EXPLORE_PROJECT_NAME}}{{USER_SUFFIX}}.{{ROUTER_ADDRESS}}/ws/info/

Please change line 23 to add a _THE_ in front of "MLB Parks" look like this:

[source,java]
----

        return new Backend("mlbparks", "THE MLB Parks", new Coordinates("39.82", "-98.57"), 5);

----

Don't forget to save the file.

##### Setup oc rsync

Not time to set up _oc rsync_. First get the name of your pod that is running the code

[source,bash,role=copypaste]
----
> oc get pods
NAME                       READY     STATUS             RESTARTS   AGE
mlbparks-3-build           0/1       Completed          0          7m
mlbparks-5-6g4wj           1/1       Running            0          4m
mongodb-mlbparks-1-jx8ht   1/1       Running            0          2h
----

Now we are set do the following command line:

[source,bash,role=copypaste]
----

oc rsync -w <location>/<to>/<your war file>/ podname:/opt/eap/standalone/deployments

which looks like for me:


----


### Remote Debugging

As you've seen so far, the web console makes it very easy to deploy things onto
OpenShift. When we d
image will ensure that:

- A database exists with the specified name
- A user exists with the specified name
- The user can access the specified database with the specified password

In the web console in your `{{EXPLORE_PROJECT_NAME}}{{USER_SUFFIX}}` project,
click the *"Add to Project"* button and then *"Browse Catalog"*. Select the *"Databases"* category and then *"Mongo"*.

image::mongodb-datastores-37.png[Data Stores]

#### Exercise: Setting up Remote Debugging
Alternatively, you could type `mongodb` in the search box. Once you have drilled down to see MongoDB, scroll down to find the *MongoDB
(Ephemeral)* template, and select it.  You will notice that there are several
MongoDB templates available.  We do not need a database with persistent storage, so the ephemeral Mongo
template is what you should choose.  Go ahead and select the ephemeral template and click the next button.

image::ocp-mongodb-template-37.png[MongoDB]

When we performed the application build, there was no template. Rather, we selected the
builder image directly and OpenShift presented only the standard build workflow.
Now we are using a template - a preconfigured set of resources that includes
parameters that can be customized. In our case, the parameters we are concerned
with are -- user, password, database, and
admin password.

image::mongo-template-deploy-37.png[MongoDB Deploy]

NOTE: Make sure you name your database service name *mongodb-nationalparks*










You can see that some of the fields say *"generated if empty"*. This is a
feature of *Templates* in OpenShift. For
now, be sure to use the following values in their respective fields:

* `MONGODB_USER` : `mongodb`
* `MONGODB_PASSWORD` : `mongodb`
* `MONGODB_DATABASE`: `mongodb`
* `MONGODB_ADMIN_PASSWORD` : `mongodb`


Once you have entered in the above information, click on "Next" to go to the next step which will allow us to add a binding.

image::mongo-create-binding.png[Bind Mongo]

This creates a *"secret"* in our project that we can use in other components, such as the national parks backend, to authenticate to the database.

While the database deploys, we will fix the labels assigned to the deployment. Currenly we can not set
a label when using templates from the Service Catalog, so in this case we will fix this manually.

Like before, we will add 3 labels:

- *__app__=workshop*  (the name we will be giving to the app)
- *__component__=nationalparks*  (the name of this deployment)
- *__role__=backend* (the role this component plays in the overall application)

Execute the following command:

[source,bash,role=copypaste]
----
$ oc label dc/mongodb-nationalparks svc/mongodb-nationalparks app=workshop component=nationalparks role=database --overwrite
----

Now that the connection and authentication information is bound to our project, we need to add it to the national parks backend.  Go to the project overview screen and click on the national parks deployment:

image::nationalparks-deployment.png[National Parks Deployment]

This will bring up the configuration for the deployment of the national parks backend.  If you think way back to the beginning of the labs, you will recall that a
*DeploymentConfiguration* tells OpenShift how to deploy something.

In order to make the authentication information available to the java code, we need to add the secret as part of the deployment by modifying the environment information.  To do this, click on *"Environment"* and then select the monogo-ephemeral-podid-credentials and click on *"Add ALL Values from ConfigMap or Secret"*.  Finally click the *"Save"* Button.

image::ocp-mongo-nationalparks-bind.png[Edit Configuration]


tion*, some
magic happened. OpenShift decided that this was a significant enough change to
warrant updating the internal version number of the *DeploymentConfiguration*. You
can verify this by looking at the output of `oc get dc`:

[source,bash]
----
NAME                    REVISION   DESIRED   CURRENT   TRIGGERED BY
mongodb-nationalparks   1          1         1         config,image(mongodb:3.2)
nationalparks           2          1         1         config,image(nationalparks:{{NATIONALPARKS_VERSION}})
parksmap                2          1         1         config,image(parksmap:{{PARKSMAP_VERSION}}))
----

Something that increments the version of a *DeploymentConfiguration*, by default,
causes a new deployment. You can verify this by looking at the output of `oc get
rc`:

[source,bash]
----
NAME                      DESIRED   CURRENT   READY     AGE
mongodb-nationalparks-1   1         1         1         24m
nationalparks-1           0         0         0         3h
nationalparks-2           1         1         1         8m
parksmap-1                0         0         0         6h
parksmap-2                1         1         1         5h
----

We see that the desired and current number of instances for the "-1" deployment
is 0. The desired and current number of instances for the "-2" deployment is 1.
This means that OpenShift has gracefully torn down our "old" application and
stood up a "new" instance.

#### Exercise: Data, Data, Everywhere

Now that we have a database deployed, we can again visit the `nationalparks` web
service to query for data:

[source,bash]
----
http://nationalparks-{{EXPLORE_PROJECT_NAME}}{{USER_SUFFIX}}.{{ROUTER_ADDRESS}}/ws/data/all
----

And the result?

[source,bash]
----
[]
----

Where's the data? Think about the process you went through. You deployed the
application and then deployed the database. Nothing actually loaded anything
*INTO* the database, though.

The application provides an endpoint to do just that:

[source,bash]
----
http://nationalparks-{{EXPLORE_PROJECT_NAME}}{{USER_SUFFIX}}.{{ROUTER_ADDRESS}}/ws/data/load
----

And the result?

[source,bash]
----
Items inserted in database: 2740
----

If you then go back to `/ws/data/all` you will see tons of JSON data now.
That's great. Our parks map should finally work!

NOTE: There's some errors reported with browsers like firefox 54 that don't properly parse the resulting JSON. It's
a browser problem, and the application is working properly. 

[source,bash]
----
http://parksmap-{{EXPLORE_PROJECT_NAME}}{{USER_SUFFIX}}.{{ROUTER_ADDRESS}}
----

Hmm... There's just one thing. The main map **STILL** isn't displaying the parks.
That's because the front end parks map only tries to talk to services that have
the right *Label*.

[NOTE]
====
You are probably wondering how the database connection magically started
working? When deploying applications to OpenShift, it is always best to use
environment variables, secrets, or configMaps to define connections to dependent systems.  This allows
for application portability across different environments.  The source file that
performs the connection as well as creates the database schema can be viewed
here:

[source,bash,role=copypaste]
----
{% if PARKSMAP_PY %}
http://{{GITLAB_URL_PREFIX}}.{{ROUTER_ADDRESS}}/{{GITLAB_USER}}/nationalparks-py/blob/{{NATIONALPARKS_VERSION}}/wsgi.py#L11-18
{% else %}
http://www.github.com/openshift-roadshow/nationalparks/blob/{{NATIONALPARKS_VERSION}}/src/main/java/com/openshift/evg/roadshow/parks/db/MongoDBConnection.java#L44-l48
{% endif %}
----

In short summary: By referring to bindings to connect to services
(like databases), it can be trivial to promote applications throughout different
lifecycle environments on OpenShift without having to modify application code.

====

#### Exercise: Working With Labels

We explored how a *Label* is just a key=value pair earlier when looking at
*Services* and *Routes* and *Selectors*. In general, a *Label* is simply an
arbitrary key=value pair. It could be anything.

* `pizza=pepperoni`
* `wicked=googly`
* `openshift=awesome`

In the case of the parks map, the application is actually querying the OpenShift
API and asking about the *Routes* and *Services* in the project. If any of them have a
*Label* that is `type=parksmap-backend`, the application knows to interrogate
the endpoints to look for map data.
{% if PARKSMAP_PY %}
You can see the code that does this link:https://github.com/openshift-roadshow/parksmap-web-py/blob/1.0.0/app.py#L97[here].
{% else %}
You can see the code that does this
link:https://github.com/openshift-roadshow/parksmap-web/blob/{{PARKSMAP_VERSION}}/src/main/java/com/openshift/evg/roadshow/rest/RouteWatcher.java#L20[here].
{% endif %}


Fortunately, the command line provides a convenient way for us to manipulate
labels. `describe` the `nationalparks` service:

[source,bash]
----
$ oc describe route nationalparks

Name:                   nationalparks
Namespace:              {{EXPLORE_PROJECT_NAME}}{{USER_SUFFIX}}
Created:                2 hours ago
Labels:                 app=workshop
                        component=nationalparks
                        role=backend
Requested Host:         nationalparks-{{EXPLORE_PROJECT_NAME}}{{USER_SUFFIX}}.{{ROUTER_ADDRESS}}
                        exposed on router router 2 hours ago
Path:                   <none>
TLS Termination:        <none>
Insecure Policy:        <none>
Endpoint Port:          8080-tcp

Service:                nationalparks
Weight:                 100 (100%)
Endpoints:              10.1.9.8:8080
----

You see that it already has some labels. Now, use `oc label`:

[source,bash]
----
$ oc label route nationalparks type=parksmap-backend
----

You will see something like:

[source,bash]
----
route "nationalparks" labeled
----

If you check your browser now:

[source,bash]
----
http://parksmap-{{EXPLORE_PROJECT_NAME}}{{USER_SUFFIX}}.{{ROUTER_ADDRESS}}/
----

image::parksmap-new-parks.png[MongoDB]

You'll notice that the parks suddenly are showing up. That's really cool!
